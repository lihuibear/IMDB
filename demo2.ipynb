{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request  # 下载文件\n",
    "import os\n",
    "import tarfile   # 解压缩文件\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer   # 建立字典\n",
    "from keras.preprocessing import sequence  # 截长补短\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Embedding, LSTM\n",
    "\n",
    "\n",
    "def rm_tags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')  # 剔除掉html标签\n",
    "    return re_tag.sub('', text)\n",
    "\n",
    "\n",
    "def read_file(filetype):  # 读取文件\n",
    "    path = \"./aclImdb/\"\n",
    "    file_list = []\n",
    "\n",
    "    positive_path = path + filetype + '/pos/'   # 正面评价的文件路径\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list += [positive_path + f]   # 存储到文件列表中\n",
    "\n",
    "    negative_path = path + filetype + '/neg/'   # 负面评价的文件路径\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list += [negative_path + f]\n",
    "\n",
    "    print(f'读取 {filetype} 文件: {len(file_list)}')   # 打印文件个数\n",
    "\n",
    "    all_labels = ([1] * 12500 + [0] * 12500)  # 前12500是正面都为1;后12500是负面都为0\n",
    "    all_texts = []\n",
    "\n",
    "    for fi in file_list:  # 读取所有文件\n",
    "        with open(fi, encoding='utf8') as file_input:\n",
    "            # 先读取文件,使用join连接所有字符串,然后使用rm_tags剔除tag最后存入列表all_texts\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "    return all_labels, all_texts\n",
    "\n",
    "\n",
    "y_train, train_text = read_file(\"train\")\n",
    "y_test, train_test = read_file(\"test\")\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "test_text = train_test\n",
    "\n",
    "\n",
    "# 建立 token\n",
    "token = Tokenizer(num_words=2000)  # 词典的单词数为2000\n",
    "# 建立token词典\n",
    "token.fit_on_texts(train_text)  # 按单词出现次数排序 取前2000个\n",
    "\n",
    "# 将影评文字转化为数字列表（一条影评文字转化为一条数字列表）\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)\n",
    "\n",
    "# 截长补短操作\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen=380)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen=380)\n",
    "\n",
    "# LSTM 模型\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim=32, input_dim=3800, input_length=380))\n",
    "# 一个单词用32维词向量表示;字典词数(维数)为3800;每个数字列表有100个数字，相当于用100个数字去表示一条评论\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))  # LSTM\n",
    "model.add(Dense(units=256, activation='relu'))  # 神经元节点数为256，激活函数为relu\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # 输出1表示正面评价,0表示负面评价,激活函数为sigmoid\n",
    "model.summary()  # 模型汇总\n",
    "\n",
    "\n",
    "# 配置\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # 定义损失函数、优化器以及评估\n",
    "# 训练\n",
    "train_history = model.fit(x=x_train, y=y_train, validation_split=0.2, epochs=10, batch_size=300, verbose=1)\n",
    "# 训练10个epoch，每一批次训练300项数据\n",
    "\n",
    "\n",
    "# 展示训练结果\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_train_history(train_history, 'accuracy', 'val_accuracy')   # 准确率折线图\n",
    "show_train_history(train_history, 'loss', 'val_loss')   # 损失函数折线图\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)  # 评估\n",
    "print(f'测试集损失: {scores[0]}')\n",
    "print(f'测试集准确率: {scores[1]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38aiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
